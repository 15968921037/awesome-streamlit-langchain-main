############################################
import streamlit as st
from langchain.llms import OpenAI
from langchain.vectorstores import Chroma
from sentence_transformers import SentenceTransformer
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.schema import AIMessage, HumanMessage

import streamlit as st
import os
from dotenv import load_dotenv  # å¯¼å…¥ dotenv åº“
from langchain_openai import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage
from langchain_core.tools import tool
from sympy import sympify, symbols, Eq, solve
from scipy.stats import norm
import functools
import operator

from langchain_core.messages import BaseMessage, HumanMessage  # å¯¼å…¥æ¶ˆæ¯ç›¸å…³çš„ç±»
from langchain_openai.chat_models import ChatOpenAI  # å¯¼å…¥ OpenAI çš„èŠå¤©æ¨¡å‹ç±»
from langgraph.prebuilt import create_react_agent  # å¯¼å…¥åˆ›å»º React é£æ ¼ä»£ç†çš„å‡½æ•°
from langgraph.graph import END, StateGraph, START  # ç”¨äºå›¾å½¢çŠ¶æ€ç®¡ç†
from langchain_core.messages import HumanMessage  # ç”¨äºåˆ›å»ºç”¨æˆ·æ¶ˆæ¯

#Define State å®šä¹‰çŠ¶æ€
import operator
from typing import Annotated, Sequence, TypedDict
from langchain_openai import ChatOpenAI



# --- åŠ è½½ .env æ–‡ä»¶ä¸­çš„å˜é‡ ---
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
api_url = os.getenv("OPENAI_API_URL")

st.title("ğŸ§® Financial calculation")

llm = ChatOpenAI(model="gpt-4o", base_url=api_url, api_key=api_key, temperature=0)



@tool
def expression_calculator(expression: str) -> str:
    """
    è®¡ç®—æ•°å­¦è¡¨è¾¾å¼çš„ç»“æœã€‚
    """
    try:
        result = sympify(expression).evalf()
        return f"{expression} = {result:.2f}"
    except Exception as e:
        return f"è¡¨è¾¾å¼è®¡ç®—å‡ºé”™ï¼š{e}"


@tool
def equation_solver(equations: list, variables: list) -> str:
    """
    è§£æ–¹ç¨‹ç»„ã€‚
    """
    try:
        sym_vars = symbols(variables)
        sym_equations = [Eq(sympify(eq.split("=")[0]), sympify(eq.split("=")[1])) for eq in equations]
        solutions = solve(sym_equations, sym_vars)
        return f"æ–¹ç¨‹ç»„çš„è§£wasï¼š{solutions}"
    except Exception as e:
        return f"æ–¹ç¨‹æ±‚è§£å‡ºé”™ï¼š{e}"

@tool
def probability_table(value: float) -> str:
    """
    æŸ¥è¯¢æ­£æ€åˆ†å¸ƒç´¯ç§¯åˆ†å¸ƒå€¼ã€‚
    """
    try:
        cdf_value = norm.cdf(value)
        return f"æ­£æ€åˆ†å¸ƒåœ¨at {value} å¤„çš„ç´¯ç§¯åˆ†å¸ƒå€¼æ˜¯ {cdf_value:.4f}"
    except Exception as e:
        return f"æ¦‚ç‡è¡¨æŸ¥è¯¢å‡ºé”™ï¼š{e}"



# å¯¼å…¥æ‰€éœ€æ¨¡å—
from typing import List, Optional  # ç”¨äºç±»å‹æ³¨è§£ï¼ŒListè¡¨ç¤ºåˆ—è¡¨ï¼ŒOptionalè¡¨ç¤ºå¯é€‰ç±»å‹
from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser  # ç”¨äºè§£æ OpenAI å‡½æ•°è°ƒç”¨çš„è¾“å‡º
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # ç”¨äºåˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿å’Œå ä½ç¬¦
from langchain_openai import ChatOpenAI  # ç”¨äºä¸ OpenAI çš„èŠå¤©æ¥å£äº¤äº’

# å¯¼å…¥å›¾å½¢å¤„ç†ç›¸å…³çš„æ¨¡å—
from langgraph.graph import END, StateGraph, START  # ç”¨äºå›¾å½¢çŠ¶æ€ç®¡ç†
from langchain_core.messages import HumanMessage  # ç”¨äºåˆ›å»ºç”¨æˆ·æ¶ˆæ¯

# å¯¼å…¥æ‰€éœ€æ¨¡å—
from typing import List, Optional  # ç”¨äºç±»å‹æ³¨è§£ï¼ŒListè¡¨ç¤ºåˆ—è¡¨ï¼ŒOptionalè¡¨ç¤ºå¯é€‰ç±»å‹
from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser  # ç”¨äºè§£æ OpenAI å‡½æ•°è°ƒç”¨çš„è¾“å‡º
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # ç”¨äºåˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿å’Œå ä½ç¬¦
from langchain_openai import ChatOpenAI  # ç”¨äºä¸ OpenAI çš„èŠå¤©æ¥å£äº¤äº’

# å¯¼å…¥å›¾å½¢å¤„ç†ç›¸å…³çš„æ¨¡å—
from langgraph.graph import END, StateGraph, START  # ç”¨äºå›¾å½¢çŠ¶æ€ç®¡ç†
from langchain_core.messages import HumanMessage  # ç”¨äºåˆ›å»ºç”¨æˆ·æ¶ˆæ¯

# å®šä¹‰ä¸€ä¸ªå›¢é˜ŸçŠ¶æ€ç±»ï¼Œç”¨äºè·Ÿè¸ªå›¢é˜Ÿæˆå‘˜å’Œä»»åŠ¡çŠ¶æ€
class CalcuTeamState(TypedDict):
    """
    ResearchTeamState ç”¨äºè¡¨ç¤ºå›¢é˜Ÿæˆå‘˜çŠ¶æ€çš„å­—å…¸ç»“æ„ã€‚æ¯ä¸ªå›¢é˜Ÿæˆå‘˜çš„æ¶ˆæ¯ä¼šè¢«è®°å½•ä¸‹æ¥ï¼Œ
    å¹¶ä¸”é€šè¿‡â€œnextâ€å­—æ®µæ¥å†³å®šä¸‹ä¸€ä¸ªåº”è¯¥æ‰§è¡Œä»»åŠ¡çš„æˆå‘˜ã€‚
    """
    # æ¯ä¸ªå›¢é˜Ÿæˆå‘˜å®Œæˆä»»åŠ¡åä¼šç”Ÿæˆä¸€æ¡æ¶ˆæ¯
    messages: Annotated[List[BaseMessage], operator.add]  # æ¶ˆæ¯åˆ—è¡¨ï¼Œè®°å½•å›¢é˜Ÿæˆå‘˜çš„æ‰€æœ‰è¾“å‡º
    # å›¢é˜Ÿæˆå‘˜çš„æŠ€èƒ½ä¿¡æ¯ï¼Œä»¥ä¾¿æ¯ä¸ªæˆå‘˜äº†è§£å…¶ä»–æˆå‘˜çš„èƒ½åŠ›
    team_members: List[str]  # å›¢é˜Ÿæˆå‘˜åˆ—è¡¨
    # ç”¨æ¥è·¯ç”±ä»»åŠ¡ï¼Œç›‘ç£è€…ä¼šæ ¹æ®å½“å‰çŠ¶æ€å†³å®šå“ªä¸ªæˆå‘˜ç»§ç»­æ‰§è¡Œä»»åŠ¡
    next: str  # å½“å‰è½®åˆ°çš„æˆå‘˜ï¼Œæˆ–è€…â€œFINISHâ€è¡¨ç¤ºä»»åŠ¡å®Œæˆ

# å®šä¹‰ä»£ç†èŠ‚ç‚¹çš„å‡½æ•°ï¼Œç”¨äºè°ƒç”¨å…·ä½“çš„ä»£ç†å¹¶è¿”å›ç»“æœ
def agent_node(state, agent, name):
    result = agent.invoke(state)  # è°ƒç”¨ä»£ç†ï¼Œä¼ å…¥çŠ¶æ€
    return {"messages": [HumanMessage(content=result["messages"][-1].content, name=name)]}  # è¿”å›ä»£ç†ç»“æœ

# åˆ›å»ºä¸€ä¸ªå›¢é˜Ÿç›‘ç£è€…å‡½æ•°ï¼Œä½œä¸ºåŸºäºLLMçš„è·¯ç”±å™¨
def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:
    """
    åˆ›å»ºä¸€ä¸ªåŸºäº LLM çš„å›¢é˜Ÿè·¯ç”±å™¨ï¼Œè´Ÿè´£é€‰æ‹©ä¸‹ä¸€ä¸ªéœ€è¦æ‰§è¡Œä»»åŠ¡çš„è§’è‰²ã€‚
    å‚æ•°:
    - llm: ä½¿ç”¨çš„èŠå¤©æ¨¡å‹ï¼Œé€šå¸¸ä¸º ChatOpenAI ç±»å‹
    - system_prompt: ç³»ç»Ÿæç¤ºï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹çš„è¡Œä¸º
    - members: ä»»åŠ¡å›¢é˜Ÿçš„æˆå‘˜åˆ—è¡¨
    
    è¿”å›:
    - è¿”å›åŒ…å«è·¯ç”±é€»è¾‘å’Œè¾“å‡ºè§£æçš„é“¾å¼å¯¹è±¡
    """
    # å®šä¹‰å¯é€‰çš„è§’è‰²ï¼ˆåŒ…æ‹¬å®Œæˆä»»åŠ¡çš„é€‰é¡¹ï¼‰
    options = ["FINISH"] + members
    
    # å®šä¹‰è·¯ç”±å‡½æ•°çš„ç»“æ„
    function_def = {
        "name": "route",  # å‡½æ•°åç§°
        "description": "Select the next role.",  # å‡½æ•°æè¿°
        "parameters": {
            "title": "routeSchema",  # å‚æ•°æ ‡é¢˜
            "type": "object",  # å‚æ•°ç±»å‹
            "properties": {
                "next": {
                    "title": "Next",  # è·¯ç”±åˆ°ä¸‹ä¸€ä¸ªè§’è‰²çš„å‚æ•°
                    "anyOf": [
                        {"enum": options},  # å¯é€‰æ‹©çš„è§’è‰²é€‰é¡¹ï¼ŒåŒ…æ‹¬â€œFINISHâ€å’Œæ‰€æœ‰å›¢é˜Ÿæˆå‘˜
                    ],
                },
            },
            "required": ["next"],  # å¿…å¡«é¡¹ï¼šnext
        },
    }
    
    # åˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿ï¼ŒåŒ…å«ç³»ç»Ÿæç¤ºå’Œå›¢é˜Ÿæˆå‘˜ä¿¡æ¯
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),  # ç³»ç»Ÿæ¶ˆæ¯ï¼Œä¼ å…¥ç»™æ¨¡å‹çš„æŒ‡ä»¤
            
            MessagesPlaceholder(variable_name="messages"),  # å ä½ç¬¦ï¼Œç”¨äºæ’å…¥å®é™…çš„æ¶ˆæ¯å†…å®¹
            (
                "system",
                "Given the conversation above, who should act next?"
                " Or should we FINISH? Select one of: {options}",  # æç¤ºæ¨¡å‹é€‰æ‹©ä¸‹ä¸€ä¸ªæ‰§è¡Œä»»åŠ¡çš„è§’è‰²
            ),
        ]
    ).partial(options=str(options), team_members=", ".join(members))  # å°†è§’è‰²é€‰é¡¹å’Œæˆå‘˜ä¿¡æ¯ä¼ é€’åˆ°æ¨¡æ¿ä¸­
    
    # è¿”å›ä¸€ä¸ªç»„åˆäº†æç¤ºæ¨¡æ¿ã€å‡½æ•°ç»‘å®šå’Œè¾“å‡ºè§£æçš„å®Œæ•´ç®¡é“
    return (
        prompt
        | llm.bind_functions(functions=[function_def], function_call="route")  # ç»‘å®šå‡½æ•°å¹¶æŒ‡å®šè°ƒç”¨å‡½æ•°
        | JsonOutputFunctionsParser()  # è¾“å‡ºè§£æå™¨ï¼Œè§£æè¿”å›çš„ JSON æ ¼å¼æ•°æ®
    )


# åˆ›å»ºé‡‘èè®¡ç®—å·¥å…·çš„ä»£ç†
calcu_tools = [expression_calculator, equation_solver, probability_table]
calcu_agent = create_react_agent(llm, tools=calcu_tools)

# æ³¨å†Œä¸ºå›¢é˜ŸèŠ‚ç‚¹
calcu_node = functools.partial(agent_node, agent=calcu_agent, name="calculation")

# å®šä¹‰ç®¡ç†è€…ä»£ç†
calcu_supervisor_node = create_team_supervisor(
    llm,
    "You are a financial assistant specialized in solving detailed calculation problems. "
    "When addressing any calculation question, follow these principles: "
    "1. Break the problem into clear, logical steps. "
    "2. Identify and explain all parameters and variables. "
    "3. Clearly state the formulas or methods used. "
    "4. Conclude with a summary of the final result and its implications. "
    "Make sure the explanation is simple enough for someone without a financial background to understand."
    "If the information is incomplete or you cannot answer,clearly state :Please ask questions about calculations", 
    ["calculation"]
)


#å°†èŠ‚ç‚¹æ·»åŠ åˆ°å›¢é˜Ÿå›¾ä¸­ï¼Œå¹¶å®šä¹‰è¾¹ï¼Œè¿™äº›è¾¹å†³å®šäº†è½¬æ¢æ¡ä»¶ã€‚
calcu_graph = StateGraph(CalcuTeamState)
# åœ¨å›¢é˜Ÿå›¾ä¸­æ·»åŠ  LocalKnowledgeBase èŠ‚ç‚¹
calcu_graph.add_node("calculation", calcu_node)
calcu_graph.add_node("supervisor", calcu_supervisor_node)

# Define the control flow
calcu_graph.add_edge("calculation", "supervisor")
calcu_graph.add_conditional_edges(
    "supervisor",
    lambda x: x["next"],
    {"calculation":"calculation", "FINISH": END},
)


calcu_graph.add_edge(START, "supervisor")
chain = calcu_graph.compile()


messages_key = "calculation_messages"  # å”¯ä¸€é”®ï¼Œç¡®ä¿å„é¡µé¢ç‹¬ç«‹

# åˆå§‹åŒ–å½“å‰é¡µé¢çš„æ¶ˆæ¯è®°å½•
if messages_key not in st.session_state:
    st.session_state[messages_key] = []  # åˆå§‹åŒ–æ¶ˆ

# --- ä¸»èŠå¤©ç•Œé¢ ---
# st.header("Chat with GPT-4o")
# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state[messages_key]:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.markdown(message.content)
    elif isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(message.content)

# è·å–ç”¨æˆ·è¾“å…¥
prompt = st.chat_input("Ask your question...")
if prompt:
    # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    st.session_state[messages_key].append(HumanMessage(content=prompt))
    with st.chat_message("user"):
        st.markdown(prompt)

    # è°ƒç”¨ LangGraph å¹¶æ˜¾ç¤ºç»“æœ
    with st.spinner("Finchat is thinking..."):
        initial_state = {"messages": st.session_state[messages_key]}
        response = chain.invoke(initial_state)

    # æ˜¾ç¤ºç»“æœ
    with st.chat_message("assistant"):
        st.markdown(response["messages"][-1].content)
        st.session_state[messages_key].append(AIMessage(content=response["messages"][-1].content))


      
#What is the step-by-step solution for calculating compound interest over 5 years at 5%?

# æ¸…ç©ºèŠå¤©è®°å½•æŒ‰é’®
if st.button("Clear Chat", key=f"clear_{messages_key}"):
    st.session_state[messages_key].clear()



with st.sidebar:
    st.image("images/Financial Academic Knowledge.jpg")