############################################
import streamlit as st
from langchain.llms import OpenAI
from langchain.vectorstores import Chroma
from sentence_transformers import SentenceTransformer
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.schema import AIMessage, HumanMessage


import os
from dotenv import load_dotenv  # å¯¼å…¥ dotenv åº“
from langchain_openai import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage
from langchain_core.tools import tool
from sympy import sympify, symbols, Eq, solve
from scipy.stats import norm
import functools
import operator

from langchain_core.messages import BaseMessage, HumanMessage  # å¯¼å…¥æ¶ˆæ¯ç›¸å…³çš„ç±»
from langchain_openai.chat_models import ChatOpenAI  # å¯¼å…¥ OpenAI çš„èŠå¤©æ¨¡å‹ç±»
from langgraph.prebuilt import create_react_agent  # å¯¼å…¥åˆ›å»º React é£æ ¼ä»£ç†çš„å‡½æ•°
from langgraph.graph import END, StateGraph, START  # ç”¨äºå›¾å½¢çŠ¶æ€ç®¡ç†
from langchain_core.messages import HumanMessage  # ç”¨äºåˆ›å»ºç”¨æˆ·æ¶ˆæ¯

#Define State å®šä¹‰çŠ¶æ€
import operator
from typing import Annotated, Sequence, TypedDict
from langchain_openai import ChatOpenAI
from langchain.llms import OpenAI
from langchain.vectorstores import Chroma
from sentence_transformers import SentenceTransformer
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.schema import AIMessage, HumanMessage
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.tools.tavily_search import TavilySearchResults

from typing import List, Optional  # ç”¨äºç±»å‹æ³¨è§£ï¼ŒListè¡¨ç¤ºåˆ—è¡¨ï¼ŒOptionalè¡¨ç¤ºå¯é€‰ç±»å‹
from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser  # ç”¨äºè§£æ OpenAI å‡½æ•°è°ƒç”¨çš„è¾“å‡º
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # ç”¨äºåˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿å’Œå ä½ç¬¦
from langchain_openai import ChatOpenAI  # ç”¨äºä¸ OpenAI çš„èŠå¤©æ¥å£äº¤äº’


# --- åŠ è½½ .env æ–‡ä»¶ä¸­çš„å˜é‡ ---
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
api_url = os.getenv("OPENAI_API_URL")

st.title("ğŸ“» Financial Current News Analysis")

llm = ChatOpenAI(model="gpt-4o", base_url=api_url, api_key=api_key, temperature=0)


# --- å®šä¹‰ scrape_webpages å·¥å…· ---
@tool
def scrape_webpages(urls: List[str]) -> str:
    """
    ä½¿ç”¨ WebBaseLoader æŠ“å–æŒ‡å®šç½‘é¡µå†…å®¹å¹¶è¿”å›ã€‚
    å‚æ•°:
    - urls: ä¸€ä¸ªåŒ…å«ç½‘é¡µ URL çš„å­—ç¬¦ä¸²åˆ—è¡¨ã€‚

    è¿”å›:
    - ä¸€ä¸ªåŒ…å«æ‰€æœ‰æŠ“å–åˆ°ç½‘é¡µå†…å®¹çš„å­—ç¬¦ä¸²ï¼Œæ¯ä¸ªç½‘é¡µå†…å®¹ä¹‹é—´ç”¨ä¸¤ä¸ªæ¢è¡Œç¬¦åˆ†éš”ã€‚
    """
    loader = WebBaseLoader(urls)
    docs = loader.load()
    return "\n\n".join(
        [f'\n{doc.page_content}\n' for doc in docs]  # æ‹¼æ¥æ–‡æ¡£å†…å®¹
    )



# å¯¼å…¥æ‰€éœ€æ¨¡å—
from typing import List, Optional  # ç”¨äºç±»å‹æ³¨è§£ï¼ŒListè¡¨ç¤ºåˆ—è¡¨ï¼ŒOptionalè¡¨ç¤ºå¯é€‰ç±»å‹
from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser  # ç”¨äºè§£æ OpenAI å‡½æ•°è°ƒç”¨çš„è¾“å‡º
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # ç”¨äºåˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿å’Œå ä½ç¬¦
from langchain_openai import ChatOpenAI  # ç”¨äºä¸ OpenAI çš„èŠå¤©æ¥å£äº¤äº’

# å¯¼å…¥å›¾å½¢å¤„ç†ç›¸å…³çš„æ¨¡å—
from langgraph.graph import END, StateGraph, START  # ç”¨äºå›¾å½¢çŠ¶æ€ç®¡ç†
from langchain_core.messages import HumanMessage  # ç”¨äºåˆ›å»ºç”¨æˆ·æ¶ˆæ¯

# å¯¼å…¥æ‰€éœ€æ¨¡å—
from typing import List, Optional  # ç”¨äºç±»å‹æ³¨è§£ï¼ŒListè¡¨ç¤ºåˆ—è¡¨ï¼ŒOptionalè¡¨ç¤ºå¯é€‰ç±»å‹
from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser  # ç”¨äºè§£æ OpenAI å‡½æ•°è°ƒç”¨çš„è¾“å‡º
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # ç”¨äºåˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿å’Œå ä½ç¬¦
from langchain_openai import ChatOpenAI  # ç”¨äºä¸ OpenAI çš„èŠå¤©æ¥å£äº¤äº’

# å¯¼å…¥å›¾å½¢å¤„ç†ç›¸å…³çš„æ¨¡å—
from langgraph.graph import END, StateGraph, START  # ç”¨äºå›¾å½¢çŠ¶æ€ç®¡ç†
from langchain_core.messages import HumanMessage  # ç”¨äºåˆ›å»ºç”¨æˆ·æ¶ˆæ¯

# å®šä¹‰ä¸€ä¸ªå›¢é˜ŸçŠ¶æ€ç±»ï¼Œç”¨äºè·Ÿè¸ªå›¢é˜Ÿæˆå‘˜å’Œä»»åŠ¡çŠ¶æ€
class CalcuTeamState(TypedDict):
    """
    ResearchTeamState ç”¨äºè¡¨ç¤ºå›¢é˜Ÿæˆå‘˜çŠ¶æ€çš„å­—å…¸ç»“æ„ã€‚æ¯ä¸ªå›¢é˜Ÿæˆå‘˜çš„æ¶ˆæ¯ä¼šè¢«è®°å½•ä¸‹æ¥ï¼Œ
    å¹¶ä¸”é€šè¿‡â€œnextâ€å­—æ®µæ¥å†³å®šä¸‹ä¸€ä¸ªåº”è¯¥æ‰§è¡Œä»»åŠ¡çš„æˆå‘˜ã€‚
    """
    # æ¯ä¸ªå›¢é˜Ÿæˆå‘˜å®Œæˆä»»åŠ¡åä¼šç”Ÿæˆä¸€æ¡æ¶ˆæ¯
    messages: Annotated[List[BaseMessage], operator.add]  # æ¶ˆæ¯åˆ—è¡¨ï¼Œè®°å½•å›¢é˜Ÿæˆå‘˜çš„æ‰€æœ‰è¾“å‡º
    # å›¢é˜Ÿæˆå‘˜çš„æŠ€èƒ½ä¿¡æ¯ï¼Œä»¥ä¾¿æ¯ä¸ªæˆå‘˜äº†è§£å…¶ä»–æˆå‘˜çš„èƒ½åŠ›
    team_members: List[str]  # å›¢é˜Ÿæˆå‘˜åˆ—è¡¨
    # ç”¨æ¥è·¯ç”±ä»»åŠ¡ï¼Œç›‘ç£è€…ä¼šæ ¹æ®å½“å‰çŠ¶æ€å†³å®šå“ªä¸ªæˆå‘˜ç»§ç»­æ‰§è¡Œä»»åŠ¡
    next: str  # å½“å‰è½®åˆ°çš„æˆå‘˜ï¼Œæˆ–è€…â€œFINISHâ€è¡¨ç¤ºä»»åŠ¡å®Œæˆ

# å®šä¹‰ä»£ç†èŠ‚ç‚¹çš„å‡½æ•°ï¼Œç”¨äºè°ƒç”¨å…·ä½“çš„ä»£ç†å¹¶è¿”å›ç»“æœ
def agent_node(state, agent, name):
    result = agent.invoke(state)  # è°ƒç”¨ä»£ç†ï¼Œä¼ å…¥çŠ¶æ€
    return {"messages": [HumanMessage(content=result["messages"][-1].content, name=name)]}  # è¿”å›ä»£ç†ç»“æœ

# åˆ›å»ºä¸€ä¸ªå›¢é˜Ÿç›‘ç£è€…å‡½æ•°ï¼Œä½œä¸ºåŸºäºLLMçš„è·¯ç”±å™¨
def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:
    """
    åˆ›å»ºä¸€ä¸ªåŸºäº LLM çš„å›¢é˜Ÿè·¯ç”±å™¨ï¼Œè´Ÿè´£é€‰æ‹©ä¸‹ä¸€ä¸ªéœ€è¦æ‰§è¡Œä»»åŠ¡çš„è§’è‰²ã€‚
    å‚æ•°:
    - llm: ä½¿ç”¨çš„èŠå¤©æ¨¡å‹ï¼Œé€šå¸¸ä¸º ChatOpenAI ç±»å‹
    - system_prompt: ç³»ç»Ÿæç¤ºï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹çš„è¡Œä¸º
    - members: ä»»åŠ¡å›¢é˜Ÿçš„æˆå‘˜åˆ—è¡¨
    
    è¿”å›:
    - è¿”å›åŒ…å«è·¯ç”±é€»è¾‘å’Œè¾“å‡ºè§£æçš„é“¾å¼å¯¹è±¡
    """
    # å®šä¹‰å¯é€‰çš„è§’è‰²ï¼ˆåŒ…æ‹¬å®Œæˆä»»åŠ¡çš„é€‰é¡¹ï¼‰
    options = ["FINISH"] + members
    
    # å®šä¹‰è·¯ç”±å‡½æ•°çš„ç»“æ„
    function_def = {
        "name": "route",  # å‡½æ•°åç§°
        "description": "Select the next role.",  # å‡½æ•°æè¿°
        "parameters": {
            "title": "routeSchema",  # å‚æ•°æ ‡é¢˜
            "type": "object",  # å‚æ•°ç±»å‹
            "properties": {
                "next": {
                    "title": "Next",  # è·¯ç”±åˆ°ä¸‹ä¸€ä¸ªè§’è‰²çš„å‚æ•°
                    "anyOf": [
                        {"enum": options},  # å¯é€‰æ‹©çš„è§’è‰²é€‰é¡¹ï¼ŒåŒ…æ‹¬â€œFINISHâ€å’Œæ‰€æœ‰å›¢é˜Ÿæˆå‘˜
                    ],
                },
            },
            "required": ["next"],  # å¿…å¡«é¡¹ï¼šnext
        },
    }
    
    # åˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿ï¼ŒåŒ…å«ç³»ç»Ÿæç¤ºå’Œå›¢é˜Ÿæˆå‘˜ä¿¡æ¯
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),  # ç³»ç»Ÿæ¶ˆæ¯ï¼Œä¼ å…¥ç»™æ¨¡å‹çš„æŒ‡ä»¤
            
            MessagesPlaceholder(variable_name="messages"),  # å ä½ç¬¦ï¼Œç”¨äºæ’å…¥å®é™…çš„æ¶ˆæ¯å†…å®¹
            (
                "system",
                "Given the conversation above, who should act next?"
                " Or should we FINISH? Select one of: {options}",  # æç¤ºæ¨¡å‹é€‰æ‹©ä¸‹ä¸€ä¸ªæ‰§è¡Œä»»åŠ¡çš„è§’è‰²
            ),
        ]
    ).partial(options=str(options), team_members=", ".join(members))  # å°†è§’è‰²é€‰é¡¹å’Œæˆå‘˜ä¿¡æ¯ä¼ é€’åˆ°æ¨¡æ¿ä¸­
    
    # è¿”å›ä¸€ä¸ªç»„åˆäº†æç¤ºæ¨¡æ¿ã€å‡½æ•°ç»‘å®šå’Œè¾“å‡ºè§£æçš„å®Œæ•´ç®¡é“
    return (
        prompt
        | llm.bind_functions(functions=[function_def], function_call="route")  # ç»‘å®šå‡½æ•°å¹¶æŒ‡å®šè°ƒç”¨å‡½æ•°
        | JsonOutputFunctionsParser()  # è¾“å‡ºè§£æå™¨ï¼Œè§£æè¿”å›çš„ JSON æ ¼å¼æ•°æ®
    )


# åˆ›å»ºä¸€ä¸ª TavilySearchResults å·¥å…·å®ä¾‹ï¼Œç”¨äºæ‰§è¡Œæœç´¢æ“ä½œï¼Œè®¾ç½®æœ€å¤§è¿”å›ç»“æœä¸º 5
tavily_tool = TavilySearchResults(max_results=5)

# åˆ›å»ºç”¨äºæœç´¢çš„ä»£ç†
search_agent = create_react_agent(llm, tools=[tavily_tool])  # ä½¿ç”¨ TavilySearchResults å·¥å…·
search_node = functools.partial(agent_node, agent=search_agent, name="Search")

# åˆ›å»ºç”¨äºç½‘é¡µæŠ“å–çš„ä»£ç†
research_agent = create_react_agent(llm, tools=[scrape_webpages])  # ä½¿ç”¨ scrape_webpages å·¥å…·
research_node = functools.partial(agent_node, agent=research_agent, name="WebScraper")

supervisor_agent = create_team_supervisor(
    llm,
    "You're an expert in financial news analysis and interpretation, specializing in simplifying complex topics for beginners."
    "Your role is to manage conversations between staff members: WebScraper and Search."
    "Always prioritize WebScraper for gathering the latest financial news."
    "If WebScraper cannot provide an answer, delegate the task to Search. When finished, reply 'FINISH'."
    "please answer easy to understand for beginners.  Follow these guidelines:"
    "1.  Summarize the news topic in one or two sentences."
    "2.  Explain the key points step-by-step (use numbered points, e.g., 1, 2, 3)."
    "3.  Highlight the potential impact of the news in a simple way (e.g., This might affect prices, jobs, or investments)."
    "Your goal is to help users understand financial news in a straightforward and beginner-friendly manner.",
    ["WebScraper", "Search"],
)

# åˆ›å»ºå›¢é˜ŸçŠ¶æ€ç±»
class ResearchTeamState(TypedDict):
    messages: List[BaseMessage]
    team_members: List[str]
    next: str

# å®šä¹‰å›¢é˜Ÿå›¾
task_graph = StateGraph(ResearchTeamState)
task_graph.add_node("WebScraper", research_node)
task_graph.add_node("Search", search_node)
task_graph.add_node("supervisor", supervisor_agent)

task_graph.add_edge("WebScraper", "supervisor")
task_graph.add_edge("Search", "supervisor")

task_graph.add_conditional_edges(
    "supervisor",
    lambda x: x["next"],
    {"WebScraper": "WebScraper", "Search": "Search", "FINISH": END},
)
task_graph.add_edge(START, "supervisor")
chain = task_graph.compile()

messages_key = "news_messages"  # å”¯ä¸€é”®ï¼Œç¡®ä¿å„é¡µé¢ç‹¬ç«‹

# åˆå§‹åŒ–å½“å‰é¡µé¢çš„æ¶ˆæ¯è®°å½•
if messages_key not in st.session_state:
    st.session_state[messages_key] = []  # åˆå§‹åŒ–æ¶ˆ

# --- ä¸»èŠå¤©ç•Œé¢ ---
# st.header("Chat with GPT-4o")
# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state[messages_key]:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.markdown(message.content)
    elif isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(message.content)

# è·å–ç”¨æˆ·è¾“å…¥
prompt = st.chat_input("Ask your question...")
if prompt:
    # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    st.session_state[messages_key].append(HumanMessage(content=prompt))
    with st.chat_message("user"):
        st.markdown(prompt)

    # è°ƒç”¨ LangGraph å¹¶æ˜¾ç¤ºç»“æœ
    with st.spinner("Finchat is thinking..."):
        initial_state = {"messages": st.session_state[messages_key]}
        response = chain.invoke(initial_state)

    # æ˜¾ç¤ºç»“æœ
    with st.chat_message("assistant"):
        st.markdown(response["messages"][-1].content)
        st.session_state[messages_key].append(AIMessage(content=response["messages"][-1].content))


      
#What is the step-by-step solution for calculating compound interest over 5 years at 5%?

# æ¸…ç©ºèŠå¤©è®°å½•æŒ‰é’®
if st.button("Clear Chat", key=f"clear_{messages_key}"):
    st.session_state[messages_key].clear()



with st.sidebar:
     st.image("./images/your_image.png")
